{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37929449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.9.1.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.21.5)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (23.1.21)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "#Install the nessasary packages from pip\n",
    "!pip install mediapipe opencv-python pandas scikit-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42c1890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the nessacary libraries from the packages\n",
    "\n",
    "#Import mediapipe to be use as the model\n",
    "import mediapipe as mp\n",
    "#Import opencv for rendaring and drawing capabilities\n",
    "import cv2\n",
    "\n",
    "import numpy as np #Handle numpy arrays\n",
    "import pandas as pd #Handle tabular data\n",
    "import csv #Handle csv files\n",
    "import os #Handle folder structure\n",
    "import glob\n",
    "import pickle #Save and oad ML model\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Partition the data into training and testing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline #Creates a pipeline\n",
    "from sklearn.preprocessing import StandardScaler #Standadize data \n",
    "\n",
    "#Classification algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score #Evaluate model through accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815e0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper to draw the landmarks and provide the landmark detection models\n",
    "draw_helpers = mp.solutions.drawing_utils \n",
    "holistic_model = mp.solutions.holistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcba964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot receive frame!\n"
     ]
    }
   ],
   "source": [
    "#DETECT AND SAVE THE LANDMARKS COORDS AS COLUMNS FROM THE SAMPLE VIDEO\n",
    "\n",
    "#Connect the sample video from the device\n",
    "sample_video = cv2.VideoCapture('1.valid.mp4')\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Exit!\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        \n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "        draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "         \n",
    "        #Display the frames    \n",
    "        cv2.imshow('Raw Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c35dc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the pose landmarks in an array \n",
    "landmarks_array = result_frame.pose_landmarks.landmark\n",
    "\n",
    "#Save the no of pose landmarks in the Array \n",
    "num_landmarks = len(landmarks_array)\n",
    "#Display landmarks\n",
    "num_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a1f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the landmarks to a table to be exported as a csv file\n",
    "\n",
    "#0th column of the table\n",
    "table_columns = ['class']\n",
    "#Add columns to the table according to the no.of landmarks\n",
    "for num in range(1, num_landmarks + 1):\n",
    "    table_columns += ['x{}'.format(num), 'y{}'.format(num), 'z{}'.format(num), 'v{}'.format(num)]\n",
    "    \n",
    "#Display columns of the table\n",
    "table_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c5c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to the csv file\n",
    "with open('data.csv', mode='w', newline='') as f:\n",
    "    #Define the csv writer\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(table_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21f0f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETECT AND SAVE COORDS OF LANDMARKS FOR EACH CLASS THROUGH THE TRAIN VIDEO\n",
    "\n",
    "def video_processor(class_name, video_pth):\n",
    "    #Connect the sample video from the device\n",
    "    sample_video = cv2.VideoCapture(video_pth)\n",
    "\n",
    "    #Load the holistic model\n",
    "    with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        #Loop through each frame of the video \n",
    "        while sample_video.isOpened():\n",
    "            #Returns the status of the read and the frame as an image\n",
    "            status, frame = sample_video.read()\n",
    "\n",
    "            #If frame is read correctly, status is true\n",
    "            if status == False:\n",
    "                print(\"Exit!\")\n",
    "                break\n",
    "\n",
    "            #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #Prevent writing and copying frame data to improve performance while making the detection\n",
    "            rgb_frame.flags.writeable = False        \n",
    "\n",
    "            #Use holistic model to make detections\n",
    "            result_frame = holistic.process(rgb_frame)\n",
    "\n",
    "            #Set frame back to writable format after detection\n",
    "            rgb_frame.flags.writeable = True   \n",
    "\n",
    "            #Recolor the captured frame from BGR for rendering with opencv\n",
    "            bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "            draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                     draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                     draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                     )\n",
    "         \n",
    "            #Export the coordinates of the landmarks to the csv file\n",
    "            try:\n",
    "\n",
    "                #Extracting all the landmarks of the pose as an array\n",
    "                pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "                #Format landmarks in to a numpy array for better structuring(removing keys) and collapse array to 1 dimesnsion\n",
    "                pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_landmarks_array]).flatten() \n",
    "                                              if result_frame.pose_landmarks else np.zeros(33*4))\n",
    "\n",
    "                #Append class name as the Oth element\n",
    "                pose_landmarks_nparray.insert(0, class_name)\n",
    "                \n",
    "                #Append the data to table in the csv file\n",
    "                with open('data.csv', mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pose_landmarks_nparray) \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #Display the frames    \n",
    "            cv2.imshow('Raw Feed', bgr_frame)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    sample_video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4b88d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit!\n"
     ]
    }
   ],
   "source": [
    "video_processor(\"Correct\", \"3.valid.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80981763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid video count :  30\n",
      "Invalid video count : 11\n"
     ]
    }
   ],
   "source": [
    "#Specify the location to the datasets\n",
    "valid_path = \"./datasets/valid/*.mp4\"\n",
    "invalid_path = \"./datasets/invalid/*.mp4\"\n",
    "\n",
    "#Displat the no of files in the datasets\n",
    "print(\"Valid Video Count: \", len(glob.glob(valid_path)))\n",
    "print(\"Invalid Video Count: \", len(glob.glob(invalid_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"Correct\"\n",
    "for i in range (1, len(glob.glob(valid_path)) + 1):\n",
    "    video_pth = \"./datasets/valid/\" + str(i) + \".mp4\"\n",
    "    video_processor(class_name, video_pth)\n",
    "    print(\"Processed: \", str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e33a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"Incorrect\"\n",
    "for i in range (1, len(glob.glob(invalid_path)) + 1):\n",
    "    video_pth = \"./datasets/invalid/\" + str(i) + \".mp4\"\n",
    "    video_processor(class_name, video_pth)\n",
    "    print(\"Processed: \", str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e172a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframe\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87eeaff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.534789</td>\n",
       "      <td>0.340018</td>\n",
       "      <td>-0.734422</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.545061</td>\n",
       "      <td>0.327873</td>\n",
       "      <td>-0.688252</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.552311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472349</td>\n",
       "      <td>0.937949</td>\n",
       "      <td>0.645837</td>\n",
       "      <td>0.759634</td>\n",
       "      <td>-0.685680</td>\n",
       "      <td>0.975963</td>\n",
       "      <td>0.406702</td>\n",
       "      <td>0.761222</td>\n",
       "      <td>-0.760625</td>\n",
       "      <td>0.981579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>0.340075</td>\n",
       "      <td>-0.679886</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.544802</td>\n",
       "      <td>0.327912</td>\n",
       "      <td>-0.635636</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.552053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587094</td>\n",
       "      <td>0.938885</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.759775</td>\n",
       "      <td>-0.824108</td>\n",
       "      <td>0.976163</td>\n",
       "      <td>0.405543</td>\n",
       "      <td>0.761442</td>\n",
       "      <td>-0.881457</td>\n",
       "      <td>0.981426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.534851</td>\n",
       "      <td>0.340163</td>\n",
       "      <td>-0.643253</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.544784</td>\n",
       "      <td>0.328017</td>\n",
       "      <td>-0.599718</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.552030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594323</td>\n",
       "      <td>0.939786</td>\n",
       "      <td>0.650265</td>\n",
       "      <td>0.759939</td>\n",
       "      <td>-0.822347</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.404899</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>-0.884187</td>\n",
       "      <td>0.981182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.534901</td>\n",
       "      <td>0.340234</td>\n",
       "      <td>-0.639145</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.544768</td>\n",
       "      <td>0.328118</td>\n",
       "      <td>-0.595136</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601119</td>\n",
       "      <td>0.940453</td>\n",
       "      <td>0.650691</td>\n",
       "      <td>0.760146</td>\n",
       "      <td>-0.839792</td>\n",
       "      <td>0.976385</td>\n",
       "      <td>0.404781</td>\n",
       "      <td>0.761661</td>\n",
       "      <td>-0.892310</td>\n",
       "      <td>0.980968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.535042</td>\n",
       "      <td>0.340296</td>\n",
       "      <td>-0.648428</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.544791</td>\n",
       "      <td>0.328195</td>\n",
       "      <td>-0.604258</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.552007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596905</td>\n",
       "      <td>0.940832</td>\n",
       "      <td>0.650841</td>\n",
       "      <td>0.760248</td>\n",
       "      <td>-0.832493</td>\n",
       "      <td>0.976366</td>\n",
       "      <td>0.404780</td>\n",
       "      <td>0.761688</td>\n",
       "      <td>-0.888286</td>\n",
       "      <td>0.980666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Correct  0.534789  0.340018 -0.734422  0.999999  0.545061  0.327873   \n",
       "1  Correct  0.534788  0.340075 -0.679886  0.999999  0.544802  0.327912   \n",
       "2  Correct  0.534851  0.340163 -0.643253  0.999999  0.544784  0.328017   \n",
       "3  Correct  0.534901  0.340234 -0.639145  0.999999  0.544768  0.328118   \n",
       "4  Correct  0.535042  0.340296 -0.648428  0.999999  0.544791  0.328195   \n",
       "\n",
       "         z2        v2        x3  ...       z31       v31       x32       y32  \\\n",
       "0 -0.688252  0.999999  0.552311  ... -0.472349  0.937949  0.645837  0.759634   \n",
       "1 -0.635636  0.999999  0.552053  ... -0.587094  0.938885  0.649047  0.759775   \n",
       "2 -0.599718  0.999999  0.552030  ... -0.594323  0.939786  0.650265  0.759939   \n",
       "3 -0.595136  0.999999  0.552000  ... -0.601119  0.940453  0.650691  0.760146   \n",
       "4 -0.604258  0.999999  0.552007  ... -0.596905  0.940832  0.650841  0.760248   \n",
       "\n",
       "        z32       v32       x33       y33       z33       v33  \n",
       "0 -0.685680  0.975963  0.406702  0.761222 -0.760625  0.981579  \n",
       "1 -0.824108  0.976163  0.405543  0.761442 -0.881457  0.981426  \n",
       "2 -0.822347  0.976234  0.404899  0.761539 -0.884187  0.981182  \n",
       "3 -0.839792  0.976385  0.404781  0.761661 -0.892310  0.980968  \n",
       "4 -0.832493  0.976366  0.404780  0.761688 -0.888286  0.980666  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "634dfa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>0.341830</td>\n",
       "      <td>-0.696658</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.535855</td>\n",
       "      <td>0.329449</td>\n",
       "      <td>-0.653082</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.541785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477941</td>\n",
       "      <td>0.931223</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.760314</td>\n",
       "      <td>-0.699613</td>\n",
       "      <td>0.974437</td>\n",
       "      <td>0.405546</td>\n",
       "      <td>0.762178</td>\n",
       "      <td>-0.757666</td>\n",
       "      <td>0.977532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.341830</td>\n",
       "      <td>-0.691384</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.535877</td>\n",
       "      <td>0.329460</td>\n",
       "      <td>-0.647774</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.541833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490456</td>\n",
       "      <td>0.931123</td>\n",
       "      <td>0.649910</td>\n",
       "      <td>0.760346</td>\n",
       "      <td>-0.720183</td>\n",
       "      <td>0.974255</td>\n",
       "      <td>0.405584</td>\n",
       "      <td>0.762178</td>\n",
       "      <td>-0.770985</td>\n",
       "      <td>0.977179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.527475</td>\n",
       "      <td>0.341830</td>\n",
       "      <td>-0.682671</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.535949</td>\n",
       "      <td>0.329476</td>\n",
       "      <td>-0.640857</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.541972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505001</td>\n",
       "      <td>0.930721</td>\n",
       "      <td>0.650216</td>\n",
       "      <td>0.760388</td>\n",
       "      <td>-0.744007</td>\n",
       "      <td>0.974045</td>\n",
       "      <td>0.405910</td>\n",
       "      <td>0.762099</td>\n",
       "      <td>-0.785265</td>\n",
       "      <td>0.976663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.527481</td>\n",
       "      <td>0.341830</td>\n",
       "      <td>-0.668001</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.535951</td>\n",
       "      <td>0.329490</td>\n",
       "      <td>-0.627740</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.541982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495164</td>\n",
       "      <td>0.930214</td>\n",
       "      <td>0.650356</td>\n",
       "      <td>0.760399</td>\n",
       "      <td>-0.727630</td>\n",
       "      <td>0.973676</td>\n",
       "      <td>0.406083</td>\n",
       "      <td>0.762012</td>\n",
       "      <td>-0.772083</td>\n",
       "      <td>0.976117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Correct</td>\n",
       "      <td>0.527493</td>\n",
       "      <td>0.341825</td>\n",
       "      <td>-0.668258</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.535957</td>\n",
       "      <td>0.329493</td>\n",
       "      <td>-0.627790</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.542005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492280</td>\n",
       "      <td>0.929735</td>\n",
       "      <td>0.650851</td>\n",
       "      <td>0.760377</td>\n",
       "      <td>-0.719618</td>\n",
       "      <td>0.973319</td>\n",
       "      <td>0.406098</td>\n",
       "      <td>0.761930</td>\n",
       "      <td>-0.766681</td>\n",
       "      <td>0.975687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1        z1        v1        x2        y2  \\\n",
       "76  Correct  0.527193  0.341830 -0.696658  0.999995  0.535855  0.329449   \n",
       "77  Correct  0.527273  0.341830 -0.691384  0.999996  0.535877  0.329460   \n",
       "78  Correct  0.527475  0.341830 -0.682671  0.999996  0.535949  0.329476   \n",
       "79  Correct  0.527481  0.341830 -0.668001  0.999996  0.535951  0.329490   \n",
       "80  Correct  0.527493  0.341825 -0.668258  0.999996  0.535957  0.329493   \n",
       "\n",
       "          z2        v2        x3  ...       z31       v31       x32       y32  \\\n",
       "76 -0.653082  0.999994  0.541785  ... -0.477941  0.931223  0.649873  0.760314   \n",
       "77 -0.647774  0.999994  0.541833  ... -0.490456  0.931123  0.649910  0.760346   \n",
       "78 -0.640857  0.999994  0.541972  ... -0.505001  0.930721  0.650216  0.760388   \n",
       "79 -0.627740  0.999995  0.541982  ... -0.495164  0.930214  0.650356  0.760399   \n",
       "80 -0.627790  0.999995  0.542005  ... -0.492280  0.929735  0.650851  0.760377   \n",
       "\n",
       "         z32       v32       x33       y33       z33       v33  \n",
       "76 -0.699613  0.974437  0.405546  0.762178 -0.757666  0.977532  \n",
       "77 -0.720183  0.974255  0.405584  0.762178 -0.770985  0.977179  \n",
       "78 -0.744007  0.974045  0.405910  0.762099 -0.785265  0.976663  \n",
       "79 -0.727630  0.973676  0.406083  0.762012 -0.772083  0.976117  \n",
       "80 -0.719618  0.973319  0.406098  0.761930 -0.766681  0.975687  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the last 5 rows in the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aa12fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Correct\n",
       "1     Correct\n",
       "2     Correct\n",
       "3     Correct\n",
       "4     Correct\n",
       "       ...   \n",
       "76    Correct\n",
       "77    Correct\n",
       "78    Correct\n",
       "79    Correct\n",
       "80    Correct\n",
       "Name: class, Length: 81, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the class column so the dataframe only contains features\n",
    "X = df.drop('class', axis=1)\n",
    "#Use the class as the target value\n",
    "Y = df['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0d4f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data with 30% for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc9a528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the machine learning model pipeline\n",
    "model_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0858e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model = model_pipeline.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75a847cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Predict the class of the test data\n",
    "output_class = model.predict(X_test.values)\n",
    "\n",
    "#Comparing the output labels with the test data labels\n",
    "print(\"Accuracy of the model: \", accuracy_score(Y_test, output_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbdbb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model as a binary file\n",
    "with open('rfc_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e93c747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the model from the binary file\n",
    "with open('rfc_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "189dcd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e610d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit!\n",
      "Class: Correct  Probability: 1.0\n"
     ]
    }
   ],
   "source": [
    "#PREDICT AND DISPLAY THE RESULTS OF THE MODEL BY PASSING THE TEST VIDEO\n",
    "\n",
    "#Connect the test video from the device\n",
    "sample_video = cv2.VideoCapture('5.invalid.mp4')\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Exit!\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        \n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "        draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "         #Predict the coordinates of the landmarks (resulrs screen)\n",
    "        try:\n",
    "            #Extracting all the landmarks of the pose as an array\n",
    "            pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "            #Format landmarks in to a numpy array for better structuring(removing keys) and collapse array to 1 dimesnsion\n",
    "            pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_landmarks_array]).flatten() \n",
    "                                          if result_frame.pose_landmarks else np.zeros(33*4))\n",
    "            \n",
    "            #Pass the numpy array into a data frame\n",
    "            features = pd.DataFrame([pose_landmarks_nparray])\n",
    "\n",
    "            #Store the top class of the prediction\n",
    "            pose_class_status = model.predict(features.values)[0]\n",
    "            #Store the probability of the prediction\n",
    "            pose_class_status_prob = model.predict_proba(features.values)[0]\n",
    "            \n",
    "            \n",
    "            #Set a rectangle box to display the results of the prediction in the video frame\n",
    "            #rectangle(container, top_coord, bottom_coord, color, line_thickness)\n",
    "            cv2.rectangle(bgr_frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            #Display the class label inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Class'\n",
    "                        , (105,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract =and display the top class of the prediction\n",
    "            cv2.putText(bgr_frame, pose_class_status.split(' ')[0]\n",
    "                        , (100,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the class probability inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Probability'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and dispthe maximum probability\n",
    "            cv2.putText(bgr_frame, str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        #Display the frames  \n",
    "\n",
    "        cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    print(\"Class:\", pose_class_status, \" Probability:\", str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2)))\n",
    "\n",
    "\n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d036497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
