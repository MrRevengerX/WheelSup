{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37929449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.9.1.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.21.5)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (23.1.21)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "#Install the nessasary packages from pip\n",
    "!pip install mediapipe opencv-python pandas scikit-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42c1890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the nessacary libraries from the packages\n",
    "\n",
    "#Import mediapipe to be use as the model\n",
    "import mediapipe as mp\n",
    "#Import opencv for rendaring and drawing capabilities\n",
    "import cv2\n",
    "\n",
    "import numpy as np #Handle numpy arrays\n",
    "import pandas as pd #Handle tabular data\n",
    "import csv #Handle csv files\n",
    "import os #Handle folder structure\n",
    "import glob\n",
    "import pickle #Save and oad ML model\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Partition the data into training and testing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline #Creates a pipeline\n",
    "from sklearn.preprocessing import StandardScaler #Standadize data \n",
    "\n",
    "#Classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score #Evaluate model through accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "815e0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper to draw the landmarks and provide the landmark detection models\n",
    "draw_helpers = mp.solutions.drawing_utils \n",
    "holistic_model = mp.solutions.holistic\n",
    "# mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c35dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of landmarks considered.\n",
    "num_landmarks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11a1f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the landmarks to a table to be exported as a csv file\n",
    "\n",
    "#0th column of the table\n",
    "table_columns = ['class']\n",
    "#Add columns to the table according to the no.of landmarks\n",
    "for num in range(1, num_landmarks + 1):\n",
    "    table_columns += ['x{}'.format(num), 'y{}'.format(num), 'z{}'.format(num), 'v{}'.format(num)]\n",
    "    \n",
    "#Display columns of the table\n",
    "table_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba577d1",
   "metadata": {},
   "source": [
    "# Creating the csv file for store extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46c5c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Created\n"
     ]
    }
   ],
   "source": [
    "csv_file_pth = 'data.csv'\n",
    "\n",
    "#Write to the csv file\n",
    "with open(csv_file_pth, mode='w', newline='') as f:\n",
    "    #Define the csv writer\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(table_columns)\n",
    "    print(\"File Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f4ea7",
   "metadata": {},
   "source": [
    "# Function to extract data from video and store inside the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21f0f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def video_processor(class_name, video_pth):\n",
    "    #Connect the sample video from the device\n",
    "    sample_video = cv2.VideoCapture(video_pth)\n",
    "    processed = False\n",
    "\n",
    "\n",
    "    #Load the holistic model\n",
    "    with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        #Loop through each frame of the video \n",
    "        while sample_video.isOpened():\n",
    "            #Returns the status of the read and the frame as an image\n",
    "            status, frame = sample_video.read()\n",
    "\n",
    "            #If frame is read correctly, status is true\n",
    "            if status == False:\n",
    "                break\n",
    "\n",
    "            #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #Prevent writing and copying frame data to improve performance while making the detection\n",
    "            rgb_frame.flags.writeable = False        \n",
    "\n",
    "            #Use holistic model to make detections\n",
    "            result_frame = holistic.process(rgb_frame)\n",
    "\n",
    "            #Set frame back to writable format after detection\n",
    "            rgb_frame.flags.writeable = True   \n",
    "\n",
    "            #Recolor the captured frame from BGR for rendering with opencv\n",
    "            bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "            draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "         \n",
    "\n",
    "            #Export the coordinates of the landmarks to the csv file\n",
    "            try:\n",
    "                pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "                # Filter out only the upper body landmarks\n",
    "                upper_body_landmarks = [pose_landmarks_array[i] for i in [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]]\n",
    "                # Format the upper body landmarks into a numpy array for better structuring and collapse the array to 1 dimension\n",
    "                pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in upper_body_landmarks]).flatten() \n",
    "                              if result_frame.pose_landmarks else np.zeros(12*4))\n",
    "\n",
    "\n",
    "                #Append class name as the Oth element\n",
    "                pose_landmarks_nparray.insert(0, class_name)\n",
    "\n",
    "                #Append the data to table in the csv file\n",
    "                with open(csv_file_pth, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pose_landmarks_nparray) \n",
    "                \n",
    "                processed = True\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #Display the frames    \n",
    "            cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    \n",
    "    sample_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #If the try block is processed without any error\n",
    "    if processed:\n",
    "        print(\"Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80981763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Video Count:  1\n",
      "Invalid Video Count:  6\n"
     ]
    }
   ],
   "source": [
    "#Specify the location to the datasets\n",
    "valid_path = \"./datasets/valid/*.mp4\"\n",
    "invalid_path = \"./datasets/invalid/*.mp4\"\n",
    "\n",
    "#Displat the no of files in the datasets\n",
    "print(\"Valid Video Count: \", len(glob.glob(valid_path)))\n",
    "print(\"Invalid Video Count: \", len(glob.glob(invalid_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e270472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  1 / 1\n",
      "Processed\n"
     ]
    }
   ],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"correct\"\n",
    "dir_size = len(glob.glob(valid_path))\n",
    "for i in range (1, dir_size + 1):\n",
    "    video_pth = \"./datasets/valid/\" + str(i) + \".mp4\"\n",
    "    print(\"Video: \", str(i), \"/\", str(dir_size))\n",
    "    video_processor(class_name, video_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da406e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  1 / 6\n",
      "Processed\n",
      "Video:  2 / 6\n",
      "Processed\n",
      "Video:  3 / 6\n",
      "Processed\n",
      "Video:  4 / 6\n",
      "Processed\n",
      "Video:  5 / 6\n",
      "Processed\n",
      "Video:  6 / 6\n",
      "Processed\n"
     ]
    }
   ],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"Incorrect\"\n",
    "dir_size = len(glob.glob(invalid_path))\n",
    "for i in range (1, dir_size + 1):\n",
    "    video_pth = \"./datasets/invalid/\" + str(i) + \".mp4\"\n",
    "    print(\"Video: \", str(i), \"/\", str(dir_size))\n",
    "    video_processor(class_name, video_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bb0b7",
   "metadata": {},
   "source": [
    "# Customize data read from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e172a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframe\n",
    "df = pd.read_csv(csv_file_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87eeaff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z10</th>\n",
       "      <th>v10</th>\n",
       "      <th>x11</th>\n",
       "      <th>y11</th>\n",
       "      <th>z11</th>\n",
       "      <th>v11</th>\n",
       "      <th>x12</th>\n",
       "      <th>y12</th>\n",
       "      <th>z12</th>\n",
       "      <th>v12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>0.619047</td>\n",
       "      <td>0.375558</td>\n",
       "      <td>-0.243535</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.409617</td>\n",
       "      <td>0.380511</td>\n",
       "      <td>-0.254297</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.782678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680581</td>\n",
       "      <td>0.990491</td>\n",
       "      <td>0.583658</td>\n",
       "      <td>0.710510</td>\n",
       "      <td>-0.128898</td>\n",
       "      <td>0.977198</td>\n",
       "      <td>0.469821</td>\n",
       "      <td>0.709493</td>\n",
       "      <td>-0.218497</td>\n",
       "      <td>0.986670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>correct</td>\n",
       "      <td>0.618967</td>\n",
       "      <td>0.375710</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.410921</td>\n",
       "      <td>0.379863</td>\n",
       "      <td>-0.289064</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.782869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680569</td>\n",
       "      <td>0.990081</td>\n",
       "      <td>0.583643</td>\n",
       "      <td>0.710109</td>\n",
       "      <td>-0.221347</td>\n",
       "      <td>0.976645</td>\n",
       "      <td>0.470897</td>\n",
       "      <td>0.706798</td>\n",
       "      <td>-0.231344</td>\n",
       "      <td>0.985518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>correct</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.375714</td>\n",
       "      <td>-0.261780</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.411287</td>\n",
       "      <td>0.379051</td>\n",
       "      <td>-0.298899</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.783430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657295</td>\n",
       "      <td>0.989982</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.709901</td>\n",
       "      <td>-0.188261</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.472224</td>\n",
       "      <td>0.706341</td>\n",
       "      <td>-0.222894</td>\n",
       "      <td>0.985131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "      <td>0.618808</td>\n",
       "      <td>0.375720</td>\n",
       "      <td>-0.274036</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.411282</td>\n",
       "      <td>0.378483</td>\n",
       "      <td>-0.307344</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.783702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.649408</td>\n",
       "      <td>0.989829</td>\n",
       "      <td>0.584304</td>\n",
       "      <td>0.709735</td>\n",
       "      <td>-0.175713</td>\n",
       "      <td>0.976184</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>0.706434</td>\n",
       "      <td>-0.209016</td>\n",
       "      <td>0.984776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correct</td>\n",
       "      <td>0.618726</td>\n",
       "      <td>0.375544</td>\n",
       "      <td>-0.273183</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.411074</td>\n",
       "      <td>0.378134</td>\n",
       "      <td>-0.306599</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.783683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.651564</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.584698</td>\n",
       "      <td>0.709414</td>\n",
       "      <td>-0.173179</td>\n",
       "      <td>0.975898</td>\n",
       "      <td>0.473210</td>\n",
       "      <td>0.706502</td>\n",
       "      <td>-0.208052</td>\n",
       "      <td>0.984446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  correct  0.619047  0.375558 -0.243535  0.999884  0.409617  0.380511   \n",
       "1  correct  0.618967  0.375710 -0.256573  0.999891  0.410921  0.379863   \n",
       "2  correct  0.618902  0.375714 -0.261780  0.999896  0.411287  0.379051   \n",
       "3  correct  0.618808  0.375720 -0.274036  0.999902  0.411282  0.378483   \n",
       "4  correct  0.618726  0.375544 -0.273183  0.999907  0.411074  0.378134   \n",
       "\n",
       "         z2        v2        x3  ...       z10       v10       x11       y11  \\\n",
       "0 -0.254297  0.999892  0.782678  ... -0.680581  0.990491  0.583658  0.710510   \n",
       "1 -0.289064  0.999891  0.782869  ... -0.680569  0.990081  0.583643  0.710109   \n",
       "2 -0.298899  0.999891  0.783430  ... -0.657295  0.989982  0.583918  0.709901   \n",
       "3 -0.307344  0.999891  0.783702  ... -0.649408  0.989829  0.584304  0.709735   \n",
       "4 -0.306599  0.999893  0.783683  ... -0.651564  0.989785  0.584698  0.709414   \n",
       "\n",
       "        z11       v11       x12       y12       z12       v12  \n",
       "0 -0.128898  0.977198  0.469821  0.709493 -0.218497  0.986670  \n",
       "1 -0.221347  0.976645  0.470897  0.706798 -0.231344  0.985518  \n",
       "2 -0.188261  0.976416  0.472224  0.706341 -0.222894  0.985131  \n",
       "3 -0.175713  0.976184  0.472952  0.706434 -0.209016  0.984776  \n",
       "4 -0.173179  0.975898  0.473210  0.706502 -0.208052  0.984446  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "634dfa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z10</th>\n",
       "      <th>v10</th>\n",
       "      <th>x11</th>\n",
       "      <th>y11</th>\n",
       "      <th>z11</th>\n",
       "      <th>v11</th>\n",
       "      <th>x12</th>\n",
       "      <th>y12</th>\n",
       "      <th>z12</th>\n",
       "      <th>v12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15251</th>\n",
       "      <td>Incorrect</td>\n",
       "      <td>0.620059</td>\n",
       "      <td>0.382603</td>\n",
       "      <td>-0.098221</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.419419</td>\n",
       "      <td>0.380915</td>\n",
       "      <td>-0.111750</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.770806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.928691</td>\n",
       "      <td>0.991005</td>\n",
       "      <td>0.665776</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>-0.594797</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.453099</td>\n",
       "      <td>0.703013</td>\n",
       "      <td>-0.708427</td>\n",
       "      <td>0.979679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15252</th>\n",
       "      <td>Incorrect</td>\n",
       "      <td>0.620094</td>\n",
       "      <td>0.382671</td>\n",
       "      <td>-0.096046</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.419462</td>\n",
       "      <td>0.381014</td>\n",
       "      <td>-0.111740</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.770414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.928643</td>\n",
       "      <td>0.991167</td>\n",
       "      <td>0.665777</td>\n",
       "      <td>0.705456</td>\n",
       "      <td>-0.595812</td>\n",
       "      <td>0.970722</td>\n",
       "      <td>0.453053</td>\n",
       "      <td>0.703011</td>\n",
       "      <td>-0.710890</td>\n",
       "      <td>0.979996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15253</th>\n",
       "      <td>Incorrect</td>\n",
       "      <td>0.620277</td>\n",
       "      <td>0.382685</td>\n",
       "      <td>-0.096509</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.419675</td>\n",
       "      <td>0.381073</td>\n",
       "      <td>-0.112089</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.770315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.925444</td>\n",
       "      <td>0.991313</td>\n",
       "      <td>0.665885</td>\n",
       "      <td>0.705477</td>\n",
       "      <td>-0.595897</td>\n",
       "      <td>0.971116</td>\n",
       "      <td>0.453051</td>\n",
       "      <td>0.703103</td>\n",
       "      <td>-0.710106</td>\n",
       "      <td>0.980360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15254</th>\n",
       "      <td>Incorrect</td>\n",
       "      <td>0.620493</td>\n",
       "      <td>0.382726</td>\n",
       "      <td>-0.096920</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.419704</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>-0.110789</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.770307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919223</td>\n",
       "      <td>0.991412</td>\n",
       "      <td>0.665960</td>\n",
       "      <td>0.705476</td>\n",
       "      <td>-0.595992</td>\n",
       "      <td>0.971434</td>\n",
       "      <td>0.453090</td>\n",
       "      <td>0.703207</td>\n",
       "      <td>-0.709133</td>\n",
       "      <td>0.980613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15255</th>\n",
       "      <td>Incorrect</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.382751</td>\n",
       "      <td>-0.094447</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.419879</td>\n",
       "      <td>0.381275</td>\n",
       "      <td>-0.106553</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.770302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918410</td>\n",
       "      <td>0.991522</td>\n",
       "      <td>0.665993</td>\n",
       "      <td>0.705455</td>\n",
       "      <td>-0.596120</td>\n",
       "      <td>0.971721</td>\n",
       "      <td>0.453107</td>\n",
       "      <td>0.703527</td>\n",
       "      <td>-0.709076</td>\n",
       "      <td>0.980894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           class        x1        y1        z1        v1        x2        y2  \\\n",
       "15251  Incorrect  0.620059  0.382603 -0.098221  0.999920  0.419419  0.380915   \n",
       "15252  Incorrect  0.620094  0.382671 -0.096046  0.999922  0.419462  0.381014   \n",
       "15253  Incorrect  0.620277  0.382685 -0.096509  0.999924  0.419675  0.381073   \n",
       "15254  Incorrect  0.620493  0.382726 -0.096920  0.999925  0.419704  0.381218   \n",
       "15255  Incorrect  0.620998  0.382751 -0.094447  0.999926  0.419879  0.381275   \n",
       "\n",
       "             z2        v2        x3  ...       z10       v10       x11  \\\n",
       "15251 -0.111750  0.999925  0.770806  ... -0.928691  0.991005  0.665776   \n",
       "15252 -0.111740  0.999927  0.770414  ... -0.928643  0.991167  0.665777   \n",
       "15253 -0.112089  0.999927  0.770315  ... -0.925444  0.991313  0.665885   \n",
       "15254 -0.110789  0.999927  0.770307  ... -0.919223  0.991412  0.665960   \n",
       "15255 -0.106553  0.999927  0.770302  ... -0.918410  0.991522  0.665993   \n",
       "\n",
       "            y11       z11       v11       x12       y12       z12       v12  \n",
       "15251  0.705403 -0.594797  0.970443  0.453099  0.703013 -0.708427  0.979679  \n",
       "15252  0.705456 -0.595812  0.970722  0.453053  0.703011 -0.710890  0.979996  \n",
       "15253  0.705477 -0.595897  0.971116  0.453051  0.703103 -0.710106  0.980360  \n",
       "15254  0.705476 -0.595992  0.971434  0.453090  0.703207 -0.709133  0.980613  \n",
       "15255  0.705455 -0.596120  0.971721  0.453107  0.703527 -0.709076  0.980894  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the last 5 rows in the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9aa12fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the class column so the dataframe only contains features\n",
    "X = df.drop('class', axis=1)\n",
    "#Use the class as the target value\n",
    "Y = df['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0d4f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data with 30% for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919b9c7",
   "metadata": {},
   "source": [
    "# Make predictions and select the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc9a528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the machine learning model pipelines\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression(max_iter=20000)),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ac8b345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store the label of the model and model after training\n",
    "train_models = {}\n",
    "for label, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train.values, Y_train.values)\n",
    "    train_models[label] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f3e2828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression(max_iter=20000))]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "352b3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9886388464059428\n",
      "rc 0.9573956740222853\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "source": [
    "#Test the accuracies of the model to choose the best classifier\n",
    "for label, model in train_models.items():\n",
    "    output_class = model.predict(X_test.values)\n",
    "    print(label, accuracy_score(Y_test.values, output_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27f39747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select and dump the classifier into a pickle file\n",
    "model = train_models['rf']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bbdbb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model as a binary file\n",
    "with open('shoulder_press.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e93c747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the model from the binary file\n",
    "with open('shoulder_press.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "189dcd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e610d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.81 0.19]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.82 0.18]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.83 0.17]\n",
      "Class: Incorrect\n",
      "[0.81 0.19]\n",
      "Class: Incorrect\n",
      "[0.8 0.2]\n",
      "Class: Incorrect\n",
      "[0.79 0.21]\n",
      "Class: Incorrect\n",
      "[0.79 0.21]\n",
      "Class: Incorrect\n",
      "[0.79 0.21]\n",
      "Class: Incorrect\n",
      "[0.79 0.21]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m rgb_frame\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m        \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#Use holistic model to make detections\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m result_frame \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#Set frame back to writable format after detection\u001b[39;00m\n\u001b[0;32m     29\u001b[0m rgb_frame\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m   \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PREDICT AND DISPLAY THE RESULTS OF THE MODEL BY PASSING THE TEST VIDEO\n",
    "\n",
    "#Connect the test video from the device\n",
    "sample_video = cv2.VideoCapture('datasets/IMG_0126.MOV')\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Done\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        \n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "        draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        #Predict the coordinates of the landmarks (resulrs screen)\n",
    "        try:\n",
    "            pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "            # Filter out only the upper body landmarks\n",
    "            upper_body_landmarks = [pose_landmarks_array[i] for i in [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]]\n",
    "            # Format the upper body landmarks into a numpy array for better structuring and collapse the array to 1 dimension\n",
    "            pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in upper_body_landmarks]).flatten() \n",
    "                              if result_frame.pose_landmarks else np.zeros(12*4))\n",
    "            #Pass the numpy array into a data frame\n",
    "            features = pd.DataFrame([pose_landmarks_nparray])\n",
    "            \n",
    "            #Store the top class of the prediction\n",
    "            pose_class_status = model.predict(features.values)[0]\n",
    "            #Store the probability of the prediction\n",
    "            pose_class_status_prob = model.predict_proba(features.values)[0]\n",
    "            \n",
    "            print(\"Class:\", pose_class_status)\n",
    "            print(pose_class_status_prob)\n",
    "            \n",
    "            #Set a rectangle box to display the results of the prediction in the video frame\n",
    "            #rectangle(container, top_coord, bottom_coord, color, line_thickness)\n",
    "            cv2.rectangle(bgr_frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            #Display the class label inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Class'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract =and display the top class of the prediction\n",
    "            cv2.putText(bgr_frame, pose_class_status.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the class probability inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Probability'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and dispthe maximum probability\n",
    "            cv2.putText(bgr_frame, str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        #Display the frames    \n",
    "        cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e06cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
