{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37929449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the nessasary packages from pip\n",
    "!pip install mediapipe opencv-python pandas scikit-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the nessacary libraries from the packages\n",
    "\n",
    "#Import mediapipe to be use as the model\n",
    "import mediapipe as mp\n",
    "#Import opencv for rendaring and drawing capabilities\n",
    "import cv2\n",
    "\n",
    "import numpy as np #Handle numpy arrays\n",
    "import pandas as pd #Handle tabular data\n",
    "import csv #Handle csv files\n",
    "import os #Handle folder structure\n",
    "import glob\n",
    "import pickle #Save and oad ML model\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Partition the data into training and testing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline #Creates a pipeline\n",
    "from sklearn.preprocessing import StandardScaler #Standadize data \n",
    "\n",
    "#Classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score #Evaluate model through accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper to draw the landmarks and provide the landmark detection models\n",
    "draw_helpers = mp.solutions.drawing_utils \n",
    "holistic_model = mp.solutions.holistic\n",
    "# mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of landmarks considered.\n",
    "num_landmarks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the landmarks to a table to be exported as a csv file\n",
    "\n",
    "#0th column of the table\n",
    "table_columns = ['class']\n",
    "#Add columns to the table according to the no.of landmarks\n",
    "for num in range(1, num_landmarks + 1):\n",
    "    table_columns += ['x{}'.format(num), 'y{}'.format(num), 'z{}'.format(num), 'v{}'.format(num)]\n",
    "    \n",
    "#Display columns of the table\n",
    "table_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba577d1",
   "metadata": {},
   "source": [
    "# Creating the csv file for store extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_pth = 'data.csv'\n",
    "\n",
    "#Write to the csv file\n",
    "with open(csv_file_pth, mode='w', newline='') as f:\n",
    "    #Define the csv writer\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(table_columns)\n",
    "    print(\"File Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f4ea7",
   "metadata": {},
   "source": [
    "# Function to extract data from video and store inside the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def video_processor(class_name, video_pth):\n",
    "    #Connect the sample video from the device\n",
    "    sample_video = cv2.VideoCapture(video_pth)\n",
    "    processed = False\n",
    "\n",
    "\n",
    "    #Load the holistic model\n",
    "    with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        #Loop through each frame of the video \n",
    "        while sample_video.isOpened():\n",
    "            #Returns the status of the read and the frame as an image\n",
    "            status, frame = sample_video.read()\n",
    "\n",
    "            #If frame is read correctly, status is true\n",
    "            if status == False:\n",
    "                break\n",
    "\n",
    "            #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #Prevent writing and copying frame data to improve performance while making the detection\n",
    "            rgb_frame.flags.writeable = False        \n",
    "\n",
    "            #Use holistic model to make detections\n",
    "            result_frame = holistic.process(rgb_frame)\n",
    "\n",
    "            #Set frame back to writable format after detection\n",
    "            rgb_frame.flags.writeable = True   \n",
    "\n",
    "            #Recolor the captured frame from BGR for rendering with opencv\n",
    "            bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "            draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "         \n",
    "\n",
    "            #Export the coordinates of the landmarks to the csv file\n",
    "            try:\n",
    "                pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "                # Filter out only the upper body landmarks\n",
    "                upper_body_landmarks = [pose_landmarks_array[i] for i in [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]]\n",
    "                # Format the upper body landmarks into a numpy array for better structuring and collapse the array to 1 dimension\n",
    "                pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in upper_body_landmarks]).flatten() \n",
    "                              if result_frame.pose_landmarks else np.zeros(12*4))\n",
    "\n",
    "\n",
    "                #Append class name as the Oth element\n",
    "                pose_landmarks_nparray.insert(0, class_name)\n",
    "\n",
    "                #Append the data to table in the csv file\n",
    "                with open(csv_file_pth, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pose_landmarks_nparray) \n",
    "                \n",
    "                processed = True\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #Display the frames    \n",
    "            cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    \n",
    "    sample_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #If the try block is processed without any error\n",
    "    if processed:\n",
    "        print(\"Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80981763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the location to the datasets\n",
    "valid_path = \"./datasets/valid/*.mp4\"\n",
    "invalid_path = \"./datasets/invalid/*.mp4\"\n",
    "\n",
    "#Displat the no of files in the datasets\n",
    "print(\"Valid Video Count: \", len(glob.glob(valid_path)))\n",
    "print(\"Invalid Video Count: \", len(glob.glob(invalid_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e270472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"correct\"\n",
    "dir_size = len(glob.glob(valid_path))\n",
    "for i in range (1, dir_size + 1):\n",
    "    video_pth = \"./datasets/valid/\" + str(i) + \".mp4\"\n",
    "    print(\"Video: \", str(i), \"/\", str(dir_size))\n",
    "    video_processor(class_name, video_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da406e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding landmarks of the invalid dataset to the csv\n",
    "class_name = \"Incorrect\"\n",
    "dir_size = len(glob.glob(invalid_path))\n",
    "for i in range (1, dir_size + 1):\n",
    "    video_pth = \"./datasets/invalid/\" + str(i) + \".mp4\"\n",
    "    print(\"Video: \", str(i), \"/\", str(dir_size))\n",
    "    video_processor(class_name, video_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bb0b7",
   "metadata": {},
   "source": [
    "# Customize data read from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframe\n",
    "df = pd.read_csv(csv_file_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eeaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first 5 rows in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the last 5 rows in the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa12fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the class column so the dataframe only contains features\n",
    "X = df.drop('class', axis=1)\n",
    "#Use the class as the target value\n",
    "Y = df['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data with 30% for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919b9c7",
   "metadata": {},
   "source": [
    "# Make predictions and select the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the machine learning model pipelines\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression(max_iter=20000)),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store the label of the model and model after training\n",
    "train_models = {}\n",
    "for label, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train.values, Y_train.values)\n",
    "    train_models[label] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the accuracies of the model to choose the best classifier\n",
    "for label, model in train_models.items():\n",
    "    output_class = model.predict(X_test.values)\n",
    "    print(label, accuracy_score(Y_test.values, output_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f39747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select and dump the classifier into a pickle file\n",
    "model = train_models['rf']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model as a binary file\n",
    "with open('shoulder_press.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the model from the binary file\n",
    "with open('shoulder_press.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dcd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e610d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT AND DISPLAY THE RESULTS OF THE MODEL BY PASSING THE TEST VIDEO\n",
    "\n",
    "#Connect the test video from the device\n",
    "sample_video = cv2.VideoCapture('datasets/IMG_0126.MOV')\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Done\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        \n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #Use pose model to detect only the landmarks of the the body and not the landmarks of the face and hand\n",
    "        draw_helpers.draw_landmarks(bgr_frame, result_frame.pose_landmarks, holistic_model.POSE_CONNECTIONS, \n",
    "                                 draw_helpers.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 draw_helpers.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        #Predict the coordinates of the landmarks (resulrs screen)\n",
    "        try:\n",
    "            pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "            # Filter out only the upper body landmarks\n",
    "            upper_body_landmarks = [pose_landmarks_array[i] for i in [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]]\n",
    "            # Format the upper body landmarks into a numpy array for better structuring and collapse the array to 1 dimension\n",
    "            pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in upper_body_landmarks]).flatten() \n",
    "                              if result_frame.pose_landmarks else np.zeros(12*4))\n",
    "            #Pass the numpy array into a data frame\n",
    "            features = pd.DataFrame([pose_landmarks_nparray])\n",
    "            \n",
    "            #Store the top class of the prediction\n",
    "            pose_class_status = model.predict(features.values)[0]\n",
    "            #Store the probability of the prediction\n",
    "            pose_class_status_prob = model.predict_proba(features.values)[0]\n",
    "            \n",
    "            print(\"Class:\", pose_class_status)\n",
    "            print(pose_class_status_prob)\n",
    "            \n",
    "            #Set a rectangle box to display the results of the prediction in the video frame\n",
    "            #rectangle(container, top_coord, bottom_coord, color, line_thickness)\n",
    "            cv2.rectangle(bgr_frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            #Display the class label inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Class'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract =and display the top class of the prediction\n",
    "            cv2.putText(bgr_frame, pose_class_status.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the class probability inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Probability'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and dispthe maximum probability\n",
    "            cv2.putText(bgr_frame, str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        #Display the frames    \n",
    "        cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e06cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
